{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of cell cycle phases by hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to extract the phases of the cell cycle from our temporal network. We do so by:\n",
    "1. Compute similarity/distance between every pair of adjacency snapshot\n",
    "2. Perform hierarchical clustering on these distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "# import pathpy as pp\n",
    "import teneto as tnt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "import scipy\n",
    "\n",
    "import seaborn as sb\n",
    "sb.set_context(\"paper\")\n",
    "\n",
    "import temp_utils as tu\n",
    "import chen2temporal_utils as c2t\n",
    "import cluster_snapshots as cs\n",
    "\n",
    "from matplotlib import animation\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our cell cycle temporal network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tedges  = pd.read_csv(\"temporal_net.tedges\") \n",
    "\n",
    "# datafile = \"tedges_combined_weighted_binary_method_percentage_p_0.5_clean2.tedges\"\n",
    "datafile = \"tedges_combined_weighted_binary_method_percentage_minmax_p_0.5_clean2.tedges\"\n",
    "\n",
    "dir_ = \"\"\n",
    "\n",
    "# datafile = \"tedges_combined_weighted_binary_method_percentage_p_0.9_clean2.tedges\"\n",
    "# dir_ = \"threshold_robustness/\"\n",
    "\n",
    "df_tedges  = pd.read_csv(datafile, sep=\"\\s*\\t\\s*\", engine='python')\n",
    "tag = datafile[25:-14]\n",
    "\n",
    "df_tedges = df_tedges.rename(columns={\"source\": \"i\", \"target\": \"j\", \"time\" : \"t\", \"weight\" : 'w'})\n",
    "\n",
    "df_tedges.head()\n",
    "\n",
    "nodes = sorted(set(df_tedges[['i', 'j']].values.flatten()))\n",
    "times = sorted(set(df_tedges['t']))\n",
    "N = len(nodes)\n",
    "\n",
    "# {label : id}\n",
    "node_ids = {key : i for i,key in enumerate(nodes)} \n",
    "# {id : label}\n",
    "node_labels = {i : key for i,key in enumerate(nodes)}\n",
    "\n",
    "df_tedges = df_tedges.replace(node_ids)\n",
    "df_tedges\n",
    "\n",
    "# /!\\ because of bug of teneto when dealing with initial time > 0, we shift all times -100\n",
    "df_tedges['t'] -= 100\n",
    "times = sorted(set(df_tedges['t']))\n",
    "\n",
    "df_tedges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnet = tnt.TemporalNetwork(from_df=df_tedges, starttime=times[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on toy snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "T = 4\n",
    "snapshots = np.random.randint(2, size=(T, N, N))\n",
    "\n",
    "# 1 Compute distances\n",
    "# -------------------\n",
    "\n",
    "# 1st test: Eucledian distance\n",
    "dist_mat = np.zeros((T, T))\n",
    "\n",
    "for i in range(T):\n",
    "    for j in range(i) :\n",
    "        dist_mat[j,i] = np.linalg.norm(snapshots[i] - snapshots[j]) # Eucledian distance\n",
    "        \n",
    "        \n",
    "# extract condensed distance matrix need for the clustering\n",
    "# id_l = np.tril_indices(n=T, k=-1) # indices of lower triangle elements\n",
    "id_u = np.triu_indices(n=T, k=1) # indices of lower triangle elements\n",
    "\n",
    "# dist_mat_condensed = dist_mat[id_l]\n",
    "dist_mat_condensed = dist_mat[id_u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat_condensed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Perform the clustering\n",
    "\n",
    "linked = shc.linkage(dist_mat_condensed, method=\"ward\")\n",
    "\n",
    "print(linked)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "dend = shc.dendrogram(linked)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on temporal network of cell cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set layout positions from agg net\n",
    "# snapshots = tnet.df_to_array()\n",
    "# snapshots = np.swapaxes(snapshots, 0, 2) # put time as zeroth axis\n",
    "# print(snapshots.shape)\n",
    "# T = tnet.T\n",
    "\n",
    "# # 1 Compute distances\n",
    "# # -------------------\n",
    "\n",
    "# # 1st test: Eucledian distance\n",
    "# dist_mat = np.zeros((T, T))\n",
    "\n",
    "# for i in range(T):\n",
    "#     for j in range(i) :\n",
    "#         dist_mat[j,i] = np.linalg.norm(snapshots[i] - snapshots[j]) # Eucledian distance\n",
    "        \n",
    "        \n",
    "# # extract condensed distance matrix need for the clustering\n",
    "# # id_l = np.tril_indices(n=T, k=-1) # indices of lower triangle elements\n",
    "# id_u = np.triu_indices(n=T, k=1) # indices of lower triangle elements\n",
    "\n",
    "# # dist_mat_condensed = dist_mat[id_l]\n",
    "# dist_mat_condensed = dist_mat[id_u]\n",
    "\n",
    "# dist_mat_full = dist_mat + dist_mat.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = tnet.T\n",
    "dist_mat, dist_mat_condensed = cs.compute_snapshot_distances(tnet, dist='eucledian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Perform the clustering\n",
    "\n",
    "linked = shc.linkage(dist_mat_condensed, method=\"ward\")\n",
    "\n",
    "# print(linked)\n",
    "cmap = cm.tab10(np.linspace(0, 1, 10))\n",
    "shc.set_link_color_palette([mpl.colors.rgb2hex(rgb[:3]) for rgb in cmap])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "dend = shc.dendrogram(linked,\n",
    "                     leaf_rotation=90,  # rotates the x axis labels\n",
    "                     leaf_font_size=8,  # font size for the x axis labels)\n",
    "                     above_threshold_color='black')\n",
    "\n",
    "ax.set_ylabel(\"Distance\")\n",
    "\n",
    "ax.set_xlabel(\"Temporal \")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Chen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xppcall import xpprun, read_pars_values_from_file\n",
    "from labellines import *\n",
    "\n",
    "npa, variables = xpprun('bychen04_xpp.ode', clean_after=True)\n",
    "\n",
    "i_st = 100\n",
    "i_end = 203\n",
    "\n",
    "times = npa[i_st:i_end,0]\n",
    "npa = npa[i_st:i_end,:]\n",
    "\n",
    "series = lambda name : npa[:, 1+variables.index(name)]\n",
    "variables = [var.upper() for var in variables]\n",
    "data = {var : series(var) for var in variables}\n",
    "\n",
    "def normed(x) :\n",
    "    return x / np.max(x)\n",
    "\n",
    "def plot_concentrations(var, times=times, ax=None, norm=False) :\n",
    "    if ax==None :\n",
    "        fig = plt.figure()\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    for i in var :\n",
    "        if norm:\n",
    "            ax.plot(times, normed(data[i]), label=i)\n",
    "        else :\n",
    "            ax.plot(times, series(i), label=i)\n",
    "\n",
    "#     ax.legend()\n",
    "    ax.set_xlabel('Time (min)')\n",
    "    if norm :\n",
    "        ax.set_ylabel('Concentration (normed)')\n",
    "    else :\n",
    "        ax.set_ylabel('Concentration')\n",
    "\n",
    "    sb.despine()\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# find minima\n",
    "id_min_mass = scipy.signal.argrelextrema(series('MASS'), np.less)\n",
    "mass_min = series('MASS')[id_min_mass]\n",
    "\n",
    "plt.plot(times, series('MASS'), 'o-')\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(times[id_min_mass], mass_min, 'ro')\n",
    "\n",
    "print(f\"min of mass: {mass_min} at indices {id_min_mass}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_events(ax=None) :\n",
    "    \n",
    "    if ax==None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    y_pos = 1.01 * ax.get_ylim()[1]\n",
    "    \n",
    "    events_chen = [33, 84,36, 100]\n",
    "    event_chen_names = ['bud', 'spn', 'ori', 'mass']\n",
    "    for i, event in enumerate(events_chen) :\n",
    "        ax.axvline(x=event, c='k', label=event_chen_names[i], zorder=-1)\n",
    "        ax.text(event, y_pos , event_chen_names[i], #transform=ax.transAxes,\n",
    "                fontsize='small', rotation=90, va='bottom', ha='center')\n",
    "\n",
    "    events = ['START', 'E3']\n",
    "    events_times = [5, 70]\n",
    "    for i, event in enumerate(events):\n",
    "        ax.axvline(x=events_times[i], c='k', ls='--', label=event[i], zorder=-1)\n",
    "        ax.text(events_times[i], y_pos, events[i], #transform=ax.transAxes,\n",
    "                fontsize='small', rotation=90, va='bottom', ha='center')\n",
    "        \n",
    "def plot_phases(ax=None, y_pos=None) :\n",
    "    \n",
    "    if ax==None:\n",
    "        ax = plt.gca()\n",
    "    if y_pos==None: \n",
    "        y_pos = 1.01 * ax.get_ylim()[1]\n",
    "\n",
    "        \n",
    "    phases = np.array([0, 35, 70, 78, 100])\n",
    "    phases_mid = (phases[:-1] + phases[1:]) / 2\n",
    "    phases_labels = ['G1', 'S', 'G2', 'M']\n",
    "\n",
    "    for i in range(len(phases)-1) :\n",
    "        ax.axvspan(xmin=phases[i], xmax=phases[i+1], ymin=0, ymax=0.1, color='k', alpha=+ 0.15*i)\n",
    "\n",
    "        ax.text(phases_mid[i], -1, phases_labels[i], fontweight='bold', \n",
    "                 va='bottom', ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_silhouette_sample(silhouette_sample, clusters, silhouette_avg, ax=None) :\n",
    "\n",
    "    if ax==None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    n_clust = len(set(clusters))\n",
    "    if n_clust > 10 :\n",
    "        sb.set_palette(\"tab20\")\n",
    "    else : \n",
    "        sb.set_palette(\"tab10\")\n",
    "        \n",
    "    y_lower = 1\n",
    "    for i in range(1, n_clust+1):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = silhouette_sample[clusters == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "#         color = plt.cm.nipy_spectral(float(i) / n_clust)\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=f\"C{i-1}\", edgecolor=f\"C{i-1}\", alpha=1)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "#         ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        hpad = 1\n",
    "        y_lower = y_upper + hpad  # 10 for the 0 samples\n",
    "\n",
    "    ax.axvline(x=silhouette_avg, c='k', ls='--')\n",
    "\n",
    "    # ax.set_ylim(1, len(clusters) + n_clust*hpad)\n",
    "\n",
    "    # ax.set_title(f\"The silhouette plot for the {n_clust} clusters.\")\n",
    "#     ax.set_xlabel(\"The silhouette coefficient values\")\n",
    "#     ax.set_ylabel(\"Cluster label\")\n",
    "#     ax.set_yticks([])\n",
    "    sb.despine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(8, 6))\n",
    "\n",
    "d_max = 2\n",
    "\n",
    "# 2. Perform the clustering\n",
    "method = \"ward\"  #\"complete\" #\"average\" #\n",
    "maxclust = 6\n",
    "\n",
    "linked = shc.linkage(dist_mat_condensed, method=method) #\"ward\")\n",
    "# clusters = shc.fcluster(linked, d_max, criterion='distance')\n",
    "clusters = shc.fcluster(linked, maxclust, criterion='maxclust')\n",
    "\n",
    "n_clusters = len(set(clusters))\n",
    "\n",
    "cmap = cm.tab10(np.linspace(0, 1, 10))\n",
    "shc.set_link_color_palette([mpl.colors.rgb2hex(rgb[:3]) for rgb in cmap])\n",
    "# print(linked)\n",
    "\n",
    "dend = shc.dendrogram(linked,\n",
    "                     leaf_rotation=90,  # rotates the x axis labels\n",
    "                     color_threshold=d_max,\n",
    "                     above_threshold_color='black',\n",
    "#                      link_color_func=lambda k: clusters[k],\n",
    "                     ax=ax1)  # font size for the x axis labels)\n",
    "\n",
    "ax1.axhline(y=d_max, c='grey', ls='--', zorder=1)\n",
    "\n",
    "ax1.set_title(f\"Dendrogram: hierarchical clustering of snapshots ({tag})\", weight=\"bold\")\n",
    "ax1.set_ylabel(\"Distance\")\n",
    "ax1.set_xlabel(\"Time indices\")\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "times = np.array(list(set(tnet.network.t))) # todo: deal with times in tnet, must be over 100\n",
    "\n",
    "n_colors = 10\n",
    "\n",
    "# colors = [f\"C{i}\" for i in clusters]\n",
    "cmap = cm.tab10\n",
    "\n",
    "sc = ax2.scatter(times, times*0, c=clusters, cmap=cmap, vmin=1, vmax=n_colors)\n",
    "\n",
    "ax2.set_yticks([])\n",
    "# ax2.set_aspect(aspect=200)\n",
    "sb.despine(ax=ax2, left=True)\n",
    "ax2.grid(axis='x')\n",
    "\n",
    "ax2.set_title(\"'Phases' extracted by hierarchical clustering of snapshots, \\n with threshold $dist_{{max}} \\\n",
    "              = {}$ => {} clusters, with '{}' method\" .format(d_max, n_clusters, method), weight=\"bold\")\n",
    "# plt.colorbar(sc, ticks=range(1,n_colors+1))\n",
    "\n",
    "\n",
    "#======================================\n",
    "\n",
    "sb.set_palette('Dark2', n_colors=8)\n",
    "var = ['CLN3', 'CLN2', 'CLB5', 'CLB2','MASS'] # +['ori']\n",
    "\n",
    "t_G1 = 0\n",
    "t_S = 36  # duration of G1, 36 min [Chen]\n",
    "t_G2 = 78\n",
    "t_M = 90\n",
    "# cycle time, 101 min [Chen]\n",
    "\n",
    "# phases = np.array([t_G1, t_S, t_G2, t_M, 100])\n",
    "phases = np.array([0, 35, 70, 78, 100])\n",
    "phases_mid = (phases[:-1] + phases[1:]) / 2\n",
    "phases_labels = ['G1', 'S', 'G2', 'M']\n",
    "\n",
    "plot_concentrations(var, times=times[:], ax=ax3, norm=True)\n",
    "labelLines(plt.gca().get_lines(),zorder=2.5, xvals=[10, 90, 95, 55, 30])\n",
    "\n",
    "for i in range(len(phases)-1) :\n",
    "    ax3.axvspan(xmin=phases[i], xmax=phases[i+1], color='k', alpha=+ 0.1*i)\n",
    "    \n",
    "    ax3.text(phases_mid[i], 1.1, phases_labels[i], fontweight='bold', \n",
    "             va='bottom', ha='center')\n",
    "\n",
    "#------------------------------------ plot events\n",
    "\n",
    "events_chen = [33, 84,36, 100]\n",
    "event_chen_names = ['bud', 'spn', 'ori', 'mass']\n",
    "for i, event in enumerate(events_chen) :\n",
    "    ax2.axvline(x=event, c='k', label=event_chen_names[i], zorder=-2)\n",
    "    ax2.text(event, 0.005, event_chen_names[i], fontsize='small', rotation=90, va='bottom', ha='right')\n",
    "\n",
    "events = ['START', 'E3']\n",
    "events_times = [5, 70]\n",
    "for i, event in enumerate(events):\n",
    "    ax2.axvline(x=events_times[i], c='k', ls='--', label=event[i], zorder=-2)\n",
    "    ax2.text(events_times[i], 0.005, events[i], fontsize='small', rotation=90, va='bottom', ha='right')\n",
    "    \n",
    "    \n",
    "# ax2.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "ax2.get_shared_x_axes().join(ax2, ax3)\n",
    "ax3.autoscale()\n",
    "plt.subplots_adjust(hspace=0.9)\n",
    "\n",
    "# plt.savefig(f\"phases_from_clustering_maxclust_{maxclust}_mtd_{method}.png\", dpi=250, bbox_inches=\"tight\")\n",
    "plt.savefig(f\"{dir_}phases_from_clustering_maxclust_{maxclust}_mtd_{method}_{tag}.png\", dpi=250, bbox_inches=\"tight\")\n",
    "plt.savefig(f\"{dir_}phases_from_clustering_maxclust_{maxclust}_mtd_{method}_{tag}.pdf\", dpi=250, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['single', 'complete', 'average', 'ward']\n",
    "i = 3\n",
    "method = methods[i]\n",
    "\n",
    "# compute dendrogram\n",
    "linked = shc.linkage(dist_mat_condensed, method=method) #\"ward\")\n",
    "\n",
    "maxclust_max = 15\n",
    "maxclust_range = range(1, maxclust_max)\n",
    "n_maxclust = len(maxclust_range)\n",
    "clusters_arr = np.zeros((n_maxclust, T))\n",
    "n_clust_arr = np.zeros(n_maxclust)\n",
    "\n",
    "silhouette_avg_arr = np.zeros((n_maxclust))\n",
    "silhouette_sample_arr = np.zeros((n_maxclust, T))\n",
    "\n",
    "times = np.array(list(set(tnet.network.t))) # todo: deal with times in tnet, must be over 100\n",
    "\n",
    "# compute array of clusters\n",
    "for i, maxclust in enumerate(maxclust_range) :\n",
    "    \n",
    "    # compute clusters\n",
    "    clusters = shc.fcluster(linked, maxclust, criterion='maxclust')\n",
    "    \n",
    "    clusters_arr[i] = clusters\n",
    "\n",
    "    n_clusters = len(set(clusters))\n",
    "    n_clust_arr[i] = n_clusters\n",
    "    \n",
    "    if n_clusters > 1 :\n",
    "        silhouette_avg = metrics.silhouette_score(dist_mat, clusters, metric=\"precomputed\")\n",
    "        silhouette_avg_arr[i] = silhouette_avg\n",
    "        \n",
    "        silhouette_sample = metrics.silhouette_samples(dist_mat, clusters, metric=\"precomputed\")\n",
    "        silhouette_sample_arr[i] = silhouette_sample \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot array of clusters   \n",
    "\n",
    "gridspec_kw={\"width_ratios\": [9,2]}\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3), gridspec_kw=gridspec_kw)\n",
    "\n",
    "#-------------- main plot with time clusters\n",
    "cs.plot_time_clusters(times, clusters_arr, ax=ax1)\n",
    "\n",
    "ax1.set_ylabel(\"Max # clusters\")\n",
    "ax1.set_xlabel(\"Times (min)\")\n",
    "\n",
    "ax1.set_xticks(range(0, 100+5, 10))\n",
    "ax1.set_ylim([-1, ax1.get_ylim()[1]])\n",
    "ax1.grid(axis=\"x\")\n",
    "ax1.set_axisbelow(True)\n",
    "sb.despine(ax=ax1)\n",
    "\n",
    "#---------------- twin plot for labels on right\n",
    "ax11 = ax1.twinx()\n",
    "ax11.set_ylim(ax1.get_ylim())\n",
    "ax11.set_yticks(maxclust_range)\n",
    "\n",
    "labels_right = [int(n_clust) if (i==0 or np.diff(n_clust_arr)[i-1]!=0) else '' for i, n_clust in enumerate(n_clust_arr)]\n",
    "ax11.set_yticklabels(labels_right)\n",
    "sb.despine(ax=ax11, right=False)\n",
    "\n",
    "# ax2.set_ylabel(\"Actual # clusters\")\n",
    "\n",
    "#----------- side plot\n",
    "# divider = make_axes_locatable(ax)\n",
    "# ax3 = divider.append_axes(\"top\", 1.2, pad=0.1, sharex=axScatter)\n",
    "# ax2 = divider.append_axes(\"right\", size=1, pad=0.5)#, sharey=ax)\n",
    "\n",
    "ax2.plot(silhouette_avg_arr, n_clust_arr, 'ko-')\n",
    "ax2.set_xlim(xmax=1.1)\n",
    "ax2.set_ylim(ax1.get_ylim())\n",
    "ax2.set_yticks(maxclust_range)\n",
    "ax2.set_yticklabels(labels_right)\n",
    "ax2.set_ylabel(\"Actual # clusters\")\n",
    "ax2.set_xlabel(\"Average silhouette\")\n",
    "\n",
    "fig.suptitle(f\"Hier. clust. method: '{method}' ({tag})\")\n",
    "\n",
    "plot_events(ax=ax1)\n",
    "plot_phases(ax=ax1)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4, top=0.8)\n",
    "\n",
    "# plt.savefig(f\"phase_clusters_all_method_{method}.png\", dpi=250, bbox_inches=\"tight\")\n",
    "plt.savefig(f\"{dir_}phase_clusters_all_method_{method}_{tag}.png\", dpi=250, bbox_inches=\"tight\")\n",
    "plt.savefig(f\"{dir_}phase_clusters_all_method_{method}_{tag}.pdf\", dpi=250, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clust_unique, idx_unique = np.unique(n_clust_arr, return_index=True) # indices of unique n_clust values\n",
    "ncols = 4\n",
    "n_unique = len(n_clust_unique) -1 # minus the 1-cluster\n",
    "nrows = n_unique // ncols + n_unique % ncols\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey=True, figsize=(10, 2 * nrows))\n",
    "\n",
    "for i, j_uni in enumerate(idx_unique): \n",
    "    \n",
    "    ax = axs.flatten()[i-1]\n",
    "    \n",
    "    n_clusters = len(set(clusters_arr[j_uni]))\n",
    "    \n",
    "    ax.set_title(f\"{n_clusters} clusters\")\n",
    "    plot_silhouette_sample(silhouette_sample_arr[j_uni], clusters_arr[j_uni], silhouette_avg_arr[j_uni], ax=ax)\n",
    "\n",
    "    \n",
    "if nrows > 1 :\n",
    "    axes_left = axs[:,0]\n",
    "else : \n",
    "    axes_left = [axs[0]]\n",
    "    \n",
    "for ax in axes_left :\n",
    "    ax.set_ylabel(\"Ordered time index\")\n",
    "\n",
    "for ax in axs.flatten()[-ncols:] :\n",
    "    ax.set_xlabel(\"Silhouette score\")\n",
    "\n",
    "fig.suptitle(f\"Sample silhouette, method: '{method}' ({tag})\")\n",
    "\n",
    "plt.subplots_adjust(top=0.8)\n",
    "\n",
    "plt.savefig(f\"{dir_}phase_clusters_silhouette_sample_method_{method}_{tag}.png\", dpi=250, bbox_inches=\"tight\")\n",
    "plt.savefig(f\"{dir_}phase_clusters_silhouette_sample_method_{method}_{tag}.pdf\", dpi=250, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots = tnet.df_to_array()\n",
    "snapshots = np.swapaxes(snapshots, 0, 2) # put time as zeroth axis\n",
    "snapshot_flat = snapshots.reshape(T, -1) # each matrix is flattened, represented as a vector\n",
    "\n",
    "print(snapshots.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods = ['single', 'complete', 'average', 'ward']\n",
    "# i = 3\n",
    "# method = methods[i]\n",
    "method = \"kmeans\"\n",
    "\n",
    "# # compute dendrogram\n",
    "# linked = shc.linkage(dist_mat_condensed, method=method) #\"ward\")\n",
    "\n",
    "maxclust_max = 15\n",
    "maxclust_range = range(1, maxclust_max)\n",
    "n_maxclust = len(maxclust_range)\n",
    "clusters_arr = np.zeros((n_maxclust, T))\n",
    "n_clust_arr = np.zeros(n_maxclust)\n",
    "\n",
    "silhouette_avg_arr = np.zeros((n_maxclust))\n",
    "silhouette_sample_arr = np.zeros((n_maxclust, T))\n",
    "\n",
    "\n",
    "# compute array of clusters\n",
    "for i, nclust in enumerate(maxclust_range) :\n",
    "    \n",
    "    # compute clusters\n",
    "#     clusters = shc.fcluster(linked, maxclust, criterion='maxclust')\n",
    "    clusters = KMeans(n_clusters=nclust, random_state=None).fit_predict(snapshot_flat)\n",
    "    \n",
    "    clusters_arr[i] = clusters\n",
    "\n",
    "    n_clusters = len(set(clusters))\n",
    "    n_clust_arr[i] = n_clusters\n",
    "    \n",
    "    if n_clusters > 1 :\n",
    "        silhouette_avg = metrics.silhouette_score(snapshot_flat, clusters, metric=\"euclidean\")\n",
    "        silhouette_avg_arr[i] = silhouette_avg\n",
    "        \n",
    "        silhouette_sample = metrics.silhouette_samples(snapshot_flat, clusters, metric=\"euclidean\")\n",
    "        silhouette_sample_arr[i] = silhouette_sample \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot array of clusters   \n",
    "\n",
    "gridspec_kw={\"width_ratios\": [9,2]}\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3), gridspec_kw=gridspec_kw)\n",
    "\n",
    "times = np.array(list(set(tnet.network.t))) # todo: deal with times in tnet, must be over 100\n",
    "#-------------- main plot with time clusters\n",
    "cs.plot_time_clusters(times, clusters_arr, ax=ax1)\n",
    "\n",
    "ax1.set_ylabel(\"Max # clusters\")\n",
    "ax1.set_xlabel(\"Times (min)\")\n",
    "\n",
    "ax1.set_xticks(range(0, 100+5, 10))\n",
    "ax1.set_ylim([-1, ax1.get_ylim()[1]])\n",
    "ax1.grid(axis=\"x\")\n",
    "ax1.set_axisbelow(True)\n",
    "sb.despine(ax=ax1)\n",
    "\n",
    "#---------------- twin plot for labels on right\n",
    "ax11 = ax1.twinx()\n",
    "ax11.set_ylim(ax1.get_ylim())\n",
    "ax11.set_yticks(maxclust_range)\n",
    "\n",
    "labels_right = [int(n_clust) if (i==0 or np.diff(n_clust_arr)[i-1]!=0) else '' for i, n_clust in enumerate(n_clust_arr)]\n",
    "ax11.set_yticklabels(labels_right)\n",
    "sb.despine(ax=ax11, right=False)\n",
    "\n",
    "# ax2.set_ylabel(\"Actual # clusters\")\n",
    "\n",
    "#----------- side plot\n",
    "# divider = make_axes_locatable(ax)\n",
    "# ax3 = divider.append_axes(\"top\", 1.2, pad=0.1, sharex=axScatter)\n",
    "# ax2 = divider.append_axes(\"right\", size=1, pad=0.5)#, sharey=ax)\n",
    "\n",
    "ax2.plot(silhouette_avg_arr, n_clust_arr, 'ko-')\n",
    "ax2.set_xlim(xmax=1.1)\n",
    "ax2.set_ylim(ax1.get_ylim())\n",
    "ax2.set_yticks(maxclust_range)\n",
    "ax2.set_yticklabels(labels_right)\n",
    "ax2.set_ylabel(\"Actual # clusters\")\n",
    "ax2.set_xlabel(\"Average silhouette\")\n",
    "\n",
    "fig.suptitle(f\"Hier. clust. method: '{method}' (with {tag})\")\n",
    "\n",
    "# cs.plot_events(ax=ax1)\n",
    "# cs.plot_phases(ax=ax1)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4, top=0.8)\n",
    "\n",
    "plt.savefig(f\"phase_clusters_kmeans_{tag}.png\", dpi=250, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "##############################\n",
    "##############################\n",
    "##############################\n",
    "##############################\n",
    "##############################\n",
    "##############################\n",
    "##############################\n",
    "##############################\n",
    "##############################\n",
    "##############################\n",
    "##############################\n",
    "##############################\n",
    "##############################\n",
    "##############################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plot_silhouette_sample(silhouette_sample, clusters, silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_clusters(times, clusters, ax=None, cmap=plt.cm.tab10) :\n",
    "\n",
    "    n_plots = len(clusters.shape)\n",
    "    n_t = len(times)\n",
    "    n_clust_arr = [len(set(clusters_i)) for clusters_i in clusters]\n",
    "\n",
    "    if n_plots > 1 : \n",
    "        for i, clusters_i in enumerate(clusters) :\n",
    "\n",
    "            n_clust = len(set(clusters_i))\n",
    "\n",
    "            ax.scatter(times, (i+1) * np.ones(n_t), c=clusters_i, \n",
    "            cmap=cmap, vmin=1, vmax=n_colors)\n",
    "\n",
    "    ax.set_ylabel(\"Max # clusters\")\n",
    "    ax.set_xlabel(\"Times (min)\")\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.set_ylim(ax.get_ylim())\n",
    "    ax2.set_yticks(maxclust_range)\n",
    "    ax2.set_yticklabels(n_clust_arr)\n",
    "    ax2.set_ylabel(\"Actual # clusters\")\n",
    "\n",
    "    ax.set_title(f\"Method: {method}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(n_clust_arr, silhouette_avg_arr, 'o-')\n",
    "\n",
    "ax.set_title(f\"Average silhouette: hier. clust. method '{method}' \")\n",
    "ax.set_xlabel(\"# clusters\")\n",
    "ax.set_ylabel(\"silhouette score\")\n",
    "\n",
    "# plt.savefig(f\"hierarchical_clustering_methods_silhouette_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"complete\"\n",
    "maxclust = 6\n",
    "\n",
    "linked = shc.linkage(dist_mat_condensed, method=method) #\"ward\")\n",
    "\n",
    "\n",
    "# clusters = shc.fcluster(linked, d_max, criterion='distance')\n",
    "clusters = shc.fcluster(linked, maxclust, criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "methods = ['single', 'complete', 'average', 'ward']\n",
    "i = 0\n",
    "method = methods[i]\n",
    "\n",
    "for i, method in enumerate(methods) :\n",
    "    \n",
    "    listsizes = []\n",
    "    scores = []\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    linked = shc.linkage(dist_mat_condensed, method=method) #\"ward\")\n",
    "\n",
    "    for nclust_max in range(2, 102):\n",
    "        clusters = shc.fcluster(linked, nclust_max, criterion='maxclust')\n",
    "    #    print(nclust,lab)\n",
    "        n_clust = max(clusters)\n",
    "    #     print(nclust_max, n_clust)\n",
    "\n",
    "        if n_clust > 1:\n",
    "            score = metrics.silhouette_score(dist_mat_full, clusters, metric=\"precomputed\")\n",
    "           # print(nclust,max(lab),lab,score) \n",
    "            listsizes.append(n_clust)\n",
    "            scores.append(score)\n",
    "    #         print(n_clust, score)\n",
    "    #         print(metrics.silhouette_samples(dist_mat_full, clusters))\n",
    "\n",
    "    plt.plot(listsizes, scores,'o-', c=f'C{i}', label=method, alpha=0.8)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title(f\"Hierarchical clustering methods comparison by average silhouette\")\n",
    "plt.xlabel(\"# clusters\")\n",
    "plt.ylabel(\"silhouette score\")\n",
    "\n",
    "# plt.savefig(f\"hierarchical_clustering_methods_silhouette_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute silhouette for each sample\n",
    "\n",
    "methods = ['single', 'complete', 'average', 'ward']\n",
    "i = 3\n",
    "method = methods[i]\n",
    "linked = shc.linkage(dist_mat_condensed, method=method) #\"ward\")\n",
    "\n",
    "nclust_max = 2\n",
    "clusters = shc.fcluster(linked, nclust_max, criterion='maxclust')\n",
    "n_clust = max(clusters)\n",
    "print(n_clust)\n",
    "\n",
    "silouhette_avg = metrics.silhouette_score(dist_mat_full, clusters, metric=\"precomputed\")\n",
    "\n",
    "\n",
    "# Compute the silhouette scores for each sample\n",
    "sample_silhouette_values = metrics.silhouette_samples(dist_mat_full, clusters, metric=\"precomputed\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "y_lower = 1\n",
    "for i in range(1, n_clust+1):\n",
    "    # Aggregate the silhouette scores for samples belonging to\n",
    "    # cluster i, and sort them\n",
    "    ith_cluster_silhouette_values = sample_silhouette_values[clusters == i]\n",
    "\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "\n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "\n",
    "    color = cm.nipy_spectral(float(i) / n_clust)\n",
    "    ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                      0, ith_cluster_silhouette_values,\n",
    "                      facecolor=f\"C{i-1}\", edgecolor=f\"C{i-1}\", alpha=1)\n",
    "\n",
    "    # Label the silhouette plots with their cluster numbers at the middle\n",
    "    ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "    # Compute the new y_lower for next plot\n",
    "    hpad = 1\n",
    "    y_lower = y_upper + hpad  # 10 for the 0 samples\n",
    "    \n",
    "ax.axvline(x=silouhette_avg, c='k', ls='--')\n",
    "\n",
    "# ax.set_ylim(1, len(clusters) + n_clust*hpad)\n",
    "\n",
    "# ax.set_title(f\"The silhouette plot for the {n_clust} clusters.\")\n",
    "ax.set_xlabel(\"The silhouette coefficient values\")\n",
    "ax.set_ylabel(\"Cluster label\")\n",
    "ax.set_yticks([])\n",
    "sb.despine()\n",
    "\n",
    "ax.set_title(f'Silhouette (sample): {method} method, {n_clust} clusters')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"sample_silhouette_method_{method}_{n_clust}_clusters.png\", dpi=250, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}