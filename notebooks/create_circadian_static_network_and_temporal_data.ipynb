{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from networkx.drawing.nx_agraph import graphviz_layout#, to_agraph #, from_agraph\n",
    "\n",
    "import seaborn as sb\n",
    "sb.set_context('paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_from_interactions(filename, sheet, source, target):\n",
    "    protein_interactions = pd.read_excel(filename, sheet_name=sheet)\n",
    "    G = nx.from_pandas_edgelist(protein_interactions, source, target)\n",
    "    return G\n",
    "\n",
    "def draw_net(G, ax=None, labels=True):\n",
    "    if ax==None :\n",
    "        ax = plt.gca()\n",
    "\n",
    "    pos = graphviz_layout(G)\n",
    "\n",
    "    params = {\n",
    "        # 'with_labels': True,\n",
    "        'node_color': 'silver',\n",
    "        'edge_color': 'silver',\n",
    "        'font_color': 'k',\n",
    "        'edgecolors' : 'k',\n",
    "        'node_size' : 150,\n",
    "        # 'node_shape' : 's',\n",
    "        'bbox' : dict(facecolor=\"mediumseagreen\", edgecolor='black', boxstyle='round, pad=0.2', alpha=1)\n",
    "    }\n",
    "    nx.draw_networkx_nodes(G, ax=ax, pos=pos, **params)\n",
    "    nx.draw_networkx_edges(G, ax=ax, pos=pos, **params)\n",
    "    \n",
    "    if labels:\n",
    "        nx.draw_networkx_labels(G, ax=ax, pos=pos, **params)\n",
    "\n",
    "    return ax\n",
    "    \n",
    "def net_info(G) :\n",
    "    return f\"{len(G)} nodes and {len(G.edges)} edges\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create graph from Y2H interactions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_Y2H = create_graph_from_interactions(\n",
    "    filename=\"../data/publications/journal.pgen.1003398.s008.xlsx\",\n",
    "    sheet=\"PPIs from Y2H screen Fig1B,C\",\n",
    "    source=\"Entrez gene ID A human\",\n",
    "    target=\"Entrez gene ID B human\")\n",
    "\n",
    "print(net_info(G_Y2H))\n",
    "fig = plt.figure(figsize=(13, 8))\n",
    "# draw_net(G_Y2H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create graph from UniHI MAN interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_unihi_man = create_graph_from_interactions(\n",
    "    filename=\"../data/publications/journal.pgen.1003398.s008.xlsx\",\n",
    "    sheet=\"Enrichment UniHI MAN Fig2\",\n",
    "    source=\"Entrez gene ID A human\",\n",
    "    target=\"Entrez gene ID B human\")\n",
    "\n",
    "print(net_info(G_unihi_man))\n",
    "fig = plt.figure(figsize=(13, 8))\n",
    "# draw_net(G_unihi_man)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create graph from extended interactions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_extension = create_graph_from_interactions(\n",
    "    filename=\"../data/publications/journal.pgen.1003398.s008.xlsx\",\n",
    "    sheet=\"Extension interactions Fig2\",\n",
    "    source=\"Entrez gene ID A\",\n",
    "    target=\"Entrez gene ID B\")\n",
    "\n",
    "print(net_info(G_extension))\n",
    "fig = plt.figure(figsize=(13, 8))\n",
    "# draw_net(G_extension)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the three networks together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_1 = G_Y2H\n",
    "G_2 = nx.compose(G_1, G_unihi_man)\n",
    "G_3 = nx.compose(G_2, G_extension)\n",
    "\n",
    "print(net_info(G_3))\n",
    "# paper says 134 proteins with 625 interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Highlight the nodes that come from the core Y2H interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(20, 15))\n",
    "# draw_net(G_3, labels=True, ax=ax)\n",
    "# pos = graphviz_layout(G_3) #\n",
    "#\n",
    "# nx.draw_networkx_nodes(G_Y2H, pos=pos, ax=ax, node_color='red')\n",
    "# nx.draw_networkx_edges(G_Y2H, pos=pos, ax=ax, edge_color='red')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save edge list to a file\n",
    "nx.write_edgelist(G_3, \"../data/static_networks/circadian_net.edgelist\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combine the two lists of expected proteins"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "proteins_core = pd.read_excel(\"../data/publications/journal.pgen.1003398.s008.xlsx\", sheet_name=\"46 circadian components Fig1\")\n",
    "proteins_core = proteins_core.iloc[:, 0:4]\n",
    "proteins_core.columns = ['entrez_human', 'entrez_mouse', 'symbol_human', 'symbol_mouse']\n",
    "\n",
    "proteins_extension = pd.read_excel(\"../data/publications/journal.pgen.1003398.s008.xlsx\", sheet_name=\"Extension proteins Fig2\")\n",
    "proteins_extension = proteins_extension.iloc[:, 1:5]\n",
    "proteins_extension.columns = ['entrez_human', 'entrez_mouse', 'symbol_human', 'symbol_mouse']\n",
    "\n",
    "proteins = pd.concat([proteins_core, proteins_extension], ignore_index=True) # 134 unique proteins\n",
    "expected_proteins = list(proteins['entrez_human'].values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For every protein that's actually involved in an interaction, add data from the 'expected proteins' table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "interacting_proteins = pd.DataFrame(G_3.nodes)\n",
    "interacting_proteins.columns = ['entrez_human']\n",
    "interacting_proteins = interacting_proteins.merge(proteins, how='left', left_on='entrez_human', right_on='entrez_human')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check all expected proteins were involved in a reaction, and vice versa"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "proteins_not_in_any_interaction = [\n",
    "    protein\n",
    "    for protein\n",
    "    in expected_proteins\n",
    "    if protein not in G_3.nodes\n",
    "]\n",
    "\n",
    "unexpected_interacting_proteins = [\n",
    "    interacting_protein\n",
    "    for interacting_protein\n",
    "    in G_3.nodes\n",
    "    if interacting_protein not in expected_proteins\n",
    "]\n",
    "\n",
    "print(sorted(unexpected_interacting_proteins))\n",
    "print(sorted(proteins_not_in_any_interaction))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Merge Affy IDs with Entrez IDs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temporal_node_data = pd.read_csv('../data/temporal_data/circadian/GSE11923_series_matrix.txt', sep='\\t', header=63, index_col=0, skipfooter=1, engine='python')\n",
    "affy_to_entrez = pd.read_csv('../data/genes/DAVID_affy_to_entrez.txt', sep='\\t', index_col=0)\n",
    "\n",
    "temporal_node_data = temporal_node_data.merge(affy_to_entrez['entrez'], how='left', left_index=True, right_index=True)\n",
    "temporal_node_data['affy'] = temporal_node_data.index\n",
    "\n",
    "temporal_node_data = interacting_proteins.merge(temporal_node_data, how='left', left_on='entrez_mouse', right_on='entrez')\n",
    "\n",
    "columns = list(temporal_node_data.columns.values)\n",
    "columns = [columns[-1]] + [columns[1], columns[0]] + [columns[3], columns[2]] + columns[4:-2]\n",
    "temporal_node_data = temporal_node_data[columns]\n",
    "columns = columns[0:5] + [i+1 for i, _ in enumerate(columns[5:])]\n",
    "temporal_node_data.columns = columns\n",
    "temporal_node_data.sort_values('entrez_mouse', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Restrict to genes of a certain cycle length\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 357 genes in static network\n",
    "#  8 hour genes: 63 in list, of which 0 are in static network\n",
    "# 12 hour genes: 260 in list, of which 7 are in static network\n",
    "# 24 hour genes: 3667 in list, of which 58 are in static network\n",
    "\n",
    "cyclic_proteins_filename = '../data/genes/24_hour_genes.XLS'\n",
    "cyclic_proteins = pd.read_excel(cyclic_proteins_filename, sheet_name='Sheet1')\n",
    "print(cyclic_proteins.shape, temporal_node_data.shape)\n",
    "temporal_node_data = temporal_node_data.merge(cyclic_proteins, how='inner', left_on='affy', right_on='Probe Set ID')\n",
    "print(temporal_node_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a table of temporal node data using the mean\n",
    "\n",
    "IMPORTANT: The Affy IDs don't match uniquely to Entrez IDs, so in lots of cases a single Entrez ID can correspond to\n",
    "several sets of temporal data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temporal_node_data_mean = pd.DataFrame()\n",
    "temporal_node_data_mean_normalised = pd.DataFrame()\n",
    "max_time = 48\n",
    "\n",
    "for entrez_human in G_3.nodes:\n",
    "    affy_proteins = temporal_node_data.loc[temporal_node_data['entrez_human'] == entrez_human]\n",
    "    if not affy_proteins.empty:\n",
    "        series = affy_proteins[affy_proteins.columns[5:5 + max_time]].T\n",
    "        mean = series.apply(lambda row: row.mean(), axis=1)\n",
    "        temporal_node_data_mean[entrez_human] = mean\n",
    "        temporal_node_data_mean_normalised[entrez_human] = mean / mean.max()\n",
    "\n",
    "temporal_node_data_mean.to_csv(f'../data/temporal_data/circadian_temporal_node_data_{pathlib.Path(cyclic_proteins_filename).stem}_mean_{max_time}.csv', sep='\\t')\n",
    "temporal_node_data_mean_normalised.to_csv(f'../data/temporal_data/circadian_temporal_node_data_{pathlib.Path(cyclic_proteins_filename).stem}_mean_{max_time}_normalised.csv', sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a table of temporal node data by just picking the first corresponding time series"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# temporal_node_data_first = pd.DataFrame()\n",
    "# temporal_node_data_first_normalised = pd.DataFrame()\n",
    "# max_time = 48\n",
    "#\n",
    "# for entrez_human in G_3.nodes:\n",
    "#     affy_proteins = temporal_node_data.loc[temporal_node_data['entrez_human'] == entrez_human]\n",
    "#     if not affy_proteins.empty:\n",
    "#         first_series = affy_proteins[affy_proteins.columns[5:5 + max_time]].iloc[0].T\n",
    "#         temporal_node_data_first[entrez_human] = first_series\n",
    "#         temporal_node_data_first_normalised[entrez_human] = first_series / first_series.max()\n",
    "#\n",
    "# temporal_node_data_first.to_csv(f'../data/temporal_data/circadian_temporal_node_data_{pathlib.Path(cyclic_proteins_filename).stem}_first_{max_time}.csv', sep='\\t')\n",
    "# temporal_node_data_first_normalised.to_csv(f'../data/temporal_data/circadian_temporal_node_data_{pathlib.Path(cyclic_proteins_filename).stem}_first_{max_time}_normalised.csv', sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Graph all of the temporal data for each Entrez ID."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Plot temporal data for each Affymetrix ID for each protein, as well as mean and normalised versions of this plot.\n",
    "# for entrez_human in G_3.nodes:\n",
    "#     affy_proteins = temporal_node_data.loc[temporal_node_data['entrez_human'] == entrez_human]\n",
    "#     series = affy_proteins[affy_proteins.columns[5:]].T\n",
    "#     mean = series.apply(lambda row: row.mean(), axis=1)\n",
    "#     normalised = series.copy()\n",
    "#     for column in list(normalised.columns):\n",
    "#         normalised[column] = normalised[column] / normalised[column].max()\n",
    "#\n",
    "#     symbol = affy_proteins[\"symbol_mouse\"].values[0]\n",
    "#     affy_ids = list(affy_proteins['affy'].values)\n",
    "#     fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(8, 3*3))\n",
    "#\n",
    "#     series.plot(ax=ax1)\n",
    "#     ax1.legend(affy_ids)\n",
    "#     ax1.set_title(f'{symbol} Actual')\n",
    "#\n",
    "#     mean.plot(ax=ax2, legend=False)\n",
    "#     ax2.set_title(f'{symbol} Mean')\n",
    "#\n",
    "#     normalised.plot(ax=ax3)\n",
    "#     ax3.legend(affy_ids)\n",
    "#     ax3.set_title(f'{symbol} Normalised')\n",
    "#\n",
    "#     fig.tight_layout()\n",
    "#     fig.savefig(f'../data/output/temporal_graphs/{symbol}.png')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}