{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "from networkx.drawing.nx_agraph import graphviz_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_from_interactions(filename, sheet, source, target):\n",
    "    protein_interactions = pd.read_excel(filename, sheet_name=sheet)\n",
    "    G = nx.from_pandas_edgelist(protein_interactions, source, target)\n",
    "    return G\n",
    "\n",
    "def draw_net(G, ax=None, labels=True):\n",
    "    if ax is None :\n",
    "        ax = plt.gca()\n",
    "\n",
    "    pos = graphviz_layout(G, prog='fdp')\n",
    "\n",
    "    params = {\n",
    "        # 'with_labels': True,\n",
    "        'node_color': 'silver',\n",
    "        'edge_color': 'silver',\n",
    "        'font_color': 'k',\n",
    "        'edgecolors' : 'k',\n",
    "        'node_size' : 150,\n",
    "        # 'node_shape' : 's',\n",
    "        'bbox' : dict(facecolor=\"mediumseagreen\", edgecolor='black', boxstyle='round, pad=0.2', alpha=1)\n",
    "    }\n",
    "    nx.draw_networkx_nodes(G, ax=ax, pos=pos, **params)\n",
    "    nx.draw_networkx_edges(G, ax=ax, pos=pos, **params)\n",
    "    \n",
    "    if labels:\n",
    "        nx.draw_networkx_labels(G, ax=ax, pos=pos, **params)\n",
    "\n",
    "    return ax\n",
    "    \n",
    "def net_info(G) :\n",
    "    return f\"{len(G)} nodes and {len(G.edges)} edges\"\n",
    "\n",
    "def highlight_subgraph(G, subgraph, ax=None, color='red', labels=True):\n",
    "    if ax is None :\n",
    "        ax = plt.gca()\n",
    "\n",
    "    draw_net(G, labels=True, ax=ax)\n",
    "    pos = graphviz_layout(G, prog='fdp')\n",
    "\n",
    "    params = {\n",
    "        # 'with_labels': True,\n",
    "        'node_color': 'red',\n",
    "        'edge_color': 'red',\n",
    "        'font_color': 'k',\n",
    "        'edgecolors' : 'k',\n",
    "        'node_size' : 150,\n",
    "        # 'node_shape' : 's',\n",
    "        'bbox' : dict(facecolor=\"red\", edgecolor='black', boxstyle='round, pad=0.2', alpha=1)\n",
    "    }\n",
    "\n",
    "    nx.draw_networkx_nodes(subgraph, pos=pos, ax=ax, **params)\n",
    "    nx.draw_networkx_edges(subgraph, pos=pos, ax=ax, **params)\n",
    "    if labels:\n",
    "        nx.draw_networkx_labels(subgraph, ax=ax, pos=pos, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create graph from Y2H interactions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_Y2H = create_graph_from_interactions(\n",
    "    filename=\"../data/publications/journal.pgen.1003398.s008.xlsx\",\n",
    "    sheet=\"PPIs from Y2H screen Fig1B,C\",\n",
    "    source=\"Entrez gene ID A human\",\n",
    "    target=\"Entrez gene ID B human\")\n",
    "\n",
    "print(net_info(G_Y2H))\n",
    "# fig = plt.figure(figsize=(13, 8))\n",
    "# draw_net(G_Y2H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create graph from UniHI MAN interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_unihi_man = create_graph_from_interactions(\n",
    "    filename=\"../data/publications/journal.pgen.1003398.s008.xlsx\",\n",
    "    sheet=\"Enrichment UniHI MAN Fig2\",\n",
    "    source=\"Entrez gene ID A human\",\n",
    "    target=\"Entrez gene ID B human\")\n",
    "\n",
    "print(net_info(G_unihi_man))\n",
    "# fig = plt.figure(figsize=(13, 8))\n",
    "# draw_net(G_unihi_man)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create graph from extended interactions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_extension = create_graph_from_interactions(\n",
    "    filename=\"../data/publications/journal.pgen.1003398.s008.xlsx\",\n",
    "    sheet=\"Extension interactions Fig2\",\n",
    "    source=\"Entrez gene ID A\",\n",
    "    target=\"Entrez gene ID B\")\n",
    "\n",
    "print(net_info(G_extension))\n",
    "# fig = plt.figure(figsize=(13, 8))\n",
    "# draw_net(G_extension)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the three networks together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_1 = G_Y2H\n",
    "G_2 = nx.compose(G_1, G_unihi_man)\n",
    "G_3 = nx.compose(G_2, G_extension)\n",
    "\n",
    "print(net_info(G_3))\n",
    "# paper says 134 nodes with 625 edges\n",
    "# Y2H network: 39 nodes and 150 edges\n",
    "# Y2H & UniHI network: 46 nodes and 212 edges\n",
    "# Full network: 134 nodes with 624 edges\n",
    "\n",
    "graph_name = 'full'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Highlight the nodes that come from the core Y2H interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "highlight_subgraph(G_3, G_Y2H, ax=ax)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combine the two lists of expected proteins"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "proteins_core = pd.read_excel(\"../data/publications/journal.pgen.1003398.s008.xlsx\", sheet_name=\"46 circadian components Fig1\")\n",
    "proteins_core = proteins_core.iloc[:, 0:4]\n",
    "proteins_core.columns = ['entrez_human', 'entrez_mouse', 'symbol_human', 'symbol_mouse']\n",
    "\n",
    "proteins_extension = pd.read_excel(\"../data/publications/journal.pgen.1003398.s008.xlsx\", sheet_name=\"Extension proteins Fig2\")\n",
    "proteins_extension = proteins_extension.iloc[:, 1:5]\n",
    "proteins_extension.columns = ['entrez_human', 'entrez_mouse', 'symbol_human', 'symbol_mouse']\n",
    "\n",
    "proteins = pd.concat([proteins_core, proteins_extension], ignore_index=True) # 134 unique proteins\n",
    "expected_proteins = list(proteins['entrez_human'].values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For every protein that's actually involved in an interaction, add data from the 'expected proteins' table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "interacting_proteins = pd.DataFrame(G_3.nodes)\n",
    "interacting_proteins.columns = ['entrez_human']\n",
    "interacting_proteins = interacting_proteins.merge(proteins, how='left', left_on='entrez_human', right_on='entrez_human')\n",
    "entrez_to_symbol = dict(zip(interacting_proteins['entrez_human'], interacting_proteins['symbol_human']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check all expected proteins were involved in a reaction, and vice versa"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "proteins_not_in_any_interaction = [\n",
    "    protein\n",
    "    for protein\n",
    "    in expected_proteins\n",
    "    if protein not in G_3.nodes\n",
    "]\n",
    "\n",
    "unexpected_interacting_proteins = [\n",
    "    interacting_protein\n",
    "    for interacting_protein\n",
    "    in G_3.nodes\n",
    "    if interacting_protein not in expected_proteins\n",
    "]\n",
    "\n",
    "print(sorted(unexpected_interacting_proteins))\n",
    "print(sorted(proteins_not_in_any_interaction))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Merge Affy IDs with Entrez IDs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temporal_node_data = pd.read_csv('../data/temporal_data/circadian/GSE11923_series_matrix.txt', sep='\\t', header=63, index_col=0, skipfooter=1, engine='python')\n",
    "affy_to_entrez = pd.read_csv('../data/genes/DAVID_affy_to_entrez.txt', sep='\\t', index_col=0)\n",
    "\n",
    "temporal_node_data = temporal_node_data.merge(affy_to_entrez['entrez'], how='left', left_index=True, right_index=True)\n",
    "temporal_node_data['affy'] = temporal_node_data.index\n",
    "\n",
    "temporal_node_data = interacting_proteins.merge(temporal_node_data, how='inner', left_on='entrez_mouse', right_on='entrez')\n",
    "\n",
    "columns = list(temporal_node_data.columns.values)\n",
    "columns = [columns[-1]] + [columns[1], columns[0]] + [columns[3], columns[2]] + columns[4:-2]\n",
    "temporal_node_data = temporal_node_data[columns]\n",
    "columns = columns[0:5] + [i+1 for i, _ in enumerate(columns[5:])]\n",
    "temporal_node_data.columns = columns\n",
    "temporal_node_data.sort_values('entrez_mouse', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Restrict to genes of a certain cycle length"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 130 genes in Y2H & UniHI network\n",
    "# 24 hour genes: 3667 in list, of which 32 are in static network\n",
    "\n",
    "# 107 genes in Y2H & UniHI network\n",
    "# 24 hour genes: 3667 in list, of which 28 are in static network\n",
    "\n",
    "# 357 genes in full static network\n",
    "#  8 hour genes: 63 in list, of which 0 are in static network\n",
    "# 12 hour genes: 260 in list, of which 7 are in static network\n",
    "# 24 hour genes: 3667 in list, of which 58 are in static network\n",
    "\n",
    "cyclic_proteins_filename = '../data/genes/24_hour_genes.XLS'\n",
    "cyclic_proteins = pd.read_excel(cyclic_proteins_filename, sheet_name='Sheet1')\n",
    "cyclic_temporal_node_data = temporal_node_data.merge(cyclic_proteins, how='inner', left_on='affy', right_on='Probe Set ID')\n",
    "\n",
    "cycle = f'{pathlib.Path(cyclic_proteins_filename).stem}_'\n",
    "# cycle = ''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot subgraph induced by cyclic genes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "symbolic_G_3 = nx.relabel_nodes(G_3, entrez_to_symbol)\n",
    "cyclic_genes_subgraph = symbolic_G_3.subgraph(cyclic_temporal_node_data['symbol_human'].values)\n",
    "print(net_info(cyclic_genes_subgraph))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "highlight_subgraph(symbolic_G_3, cyclic_genes_subgraph, ax=ax)\n",
    "plt.savefig(f'../data/output/{graph_name}_circadian_network_with_24h_genes_subgraph.png', dpi=300)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a table of temporal node data using the mean\n",
    "\n",
    "IMPORTANT: The Affy IDs don't match uniquely to Entrez IDs, so in lots of cases a single Entrez ID can correspond to\n",
    "several sets of temporal data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temporal_node_data_mean = pd.DataFrame()\n",
    "temporal_node_data_mean_normalised = pd.DataFrame()\n",
    "max_time = 48\n",
    "\n",
    "# ToDo: use 'groupby' here instead!\n",
    "for entrez_human in G_3.nodes:\n",
    "    affy_proteins = temporal_node_data.loc[temporal_node_data['entrez_human'] == entrez_human]\n",
    "    if affy_proteins.empty:\n",
    "        print(f'Human entrez ID {entrez_human} either has no temporal data or no affy ID')\n",
    "    else:\n",
    "        symbol = affy_proteins['symbol_human'].values[0]\n",
    "        series = affy_proteins[affy_proteins.columns[5:5 + max_time]].T\n",
    "        mean = series.apply(lambda row: row.mean(), axis=1)\n",
    "        temporal_node_data_mean[symbol] = mean\n",
    "        difference = mean.max() - mean.min()\n",
    "        temporal_node_data_mean_normalised[symbol] = (mean - mean.min()) / difference\n",
    "\n",
    "temporal_node_data_mean.to_csv(f'../data/temporal_data/circadian/circadian_temporal_node_data_{cycle}mean_{graph_name}.csv', sep='\\t')\n",
    "temporal_node_data_mean_normalised.to_csv(f'../data/temporal_data/circadian/circadian_temporal_node_data_{cycle}mean_normalised_{graph_name}.csv', sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a table of temporal node data by just picking the first corresponding time series"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# temporal_node_data_first = pd.DataFrame()\n",
    "# temporal_node_data_first_normalised = pd.DataFrame()\n",
    "# max_time = 48\n",
    "#\n",
    "# for entrez_human in G_3.nodes:\n",
    "#     affy_proteins = temporal_node_data.loc[temporal_node_data['entrez_human'] == entrez_human]\n",
    "#     if not affy_proteins.empty:\n",
    "#         first_series = affy_proteins[affy_proteins.columns[5:5 + max_time]].iloc[0].T\n",
    "#         temporal_node_data_first[entrez_human] = first_series\n",
    "#         temporal_node_data_first_normalised[entrez_human] = first_series / first_series.max()\n",
    "#\n",
    "# temporal_node_data_first.to_csv(f'../data/temporal_data/circadian_temporal_node_data_{pathlib.Path(cyclic_proteins_filename).stem}_first_{max_time}.csv', sep='\\t')\n",
    "# temporal_node_data_first_normalised.to_csv(f'../data/temporal_data/circadian_temporal_node_data_{pathlib.Path(cyclic_proteins_filename).stem}_first_{max_time}_normalised.csv', sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Graph all of the temporal data for each Entrez ID."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# max_time = 48\n",
    "#\n",
    "# # Plot temporal data for each Affymetrix ID for each protein, as well as mean and normalised versions of this plot.\n",
    "# for entrez_human in G_3.nodes:\n",
    "#     affy_proteins = temporal_node_data.loc[temporal_node_data['entrez_human'] == entrez_human]\n",
    "#     if affy_proteins.empty:\n",
    "#         print(f'No data for {entrez_human}')\n",
    "#     else:\n",
    "#         series = affy_proteins[affy_proteins.columns[5:5 + max_time]].T\n",
    "#         mean = series.apply(lambda row: row.mean(), axis=1)\n",
    "#         normalised = series.copy()\n",
    "#         for column in list(normalised.columns):\n",
    "#             minimum = normalised[column].min()\n",
    "#             difference = normalised[column].max() - minimum\n",
    "#             normalised[column] = (normalised[column] - minimum) / difference\n",
    "#\n",
    "#         symbol = affy_proteins[\"symbol_mouse\"].values[0]\n",
    "#         affy_ids = list(affy_proteins['affy'].values)\n",
    "#         fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(8, 3*3))\n",
    "#\n",
    "#         series.plot(ax=ax1)\n",
    "#         ax1.legend(affy_ids)\n",
    "#         ax1.set_title(f'{symbol} Actual')\n",
    "#\n",
    "#         mean.plot(ax=ax2, legend=False)\n",
    "#         ax2.set_title(f'{symbol} Mean')\n",
    "#\n",
    "#         normalised.plot(ax=ax3)\n",
    "#         ax3.legend(affy_ids)\n",
    "#         ax3.set_title(f'{symbol} Normalised')\n",
    "#\n",
    "#\n",
    "#         fig.tight_layout()\n",
    "#         fig.savefig(f'../data/output/all_genes/{symbol}.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save edge list to a file\n",
    "nx.relabel_nodes(G_3, entrez_to_symbol, copy=False)\n",
    "nx.write_edgelist(G_3, f\"../data/static_networks/circadian_{graph_name}.edgelist\", delimiter=', ')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}